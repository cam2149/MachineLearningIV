{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 91296,
          "databundleVersionId": 10829413,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 30840,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "Training",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cam2149/MachineLearningIV/blob/main/Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "sBcdo-zrK2b1"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "aa_iv_2025_i_object_localization_path = kagglehub.competition_download('aa-iv-2025-i-object-localization')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "lzKteu5mK2b4"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchsummary\n",
        "!pip install -U albumentations"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T22:59:11.627798Z",
          "iopub.execute_input": "2025-02-15T22:59:11.628086Z",
          "iopub.status.idle": "2025-02-15T22:59:18.215766Z",
          "shell.execute_reply.started": "2025-02-15T22:59:11.628065Z",
          "shell.execute_reply": "2025-02-15T22:59:18.214717Z"
        },
        "id": "iIP8G574K2b6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "RfAA3HShK2b7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import copy\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import Tensor\n",
        "from torch.optim import Optimizer\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from multiprocessing import cpu_count\n",
        "\n",
        "import typing as ty\n",
        "from numpy.typing import NDArray\n",
        "import os\n",
        "import os.path as osp\n",
        "\n",
        "import albumentations as A\n",
        "import torchvision\n",
        "from skimage import io, transform\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "from functools import reduce\n",
        "from torchsummary import summary\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T22:59:18.217076Z",
          "iopub.execute_input": "2025-02-15T22:59:18.217428Z",
          "iopub.status.idle": "2025-02-15T22:59:18.223343Z",
          "shell.execute_reply.started": "2025-02-15T22:59:18.2174Z",
          "shell.execute_reply": "2025-02-15T22:59:18.222416Z"
        },
        "id": "PojUsH_IK2b8"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Config"
      ],
      "metadata": {
        "id": "_bRkGhjCK2b9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    \"DATA_DIR\": \"/kaggle/input/aa-iv-2025-i-object-localization/\",\n",
        "    \"WORK_DIR\": \"/kaggle/working\",\n",
        "    \"IMG_DIR\": \"images/images\",\n",
        "    \"TRAIN_CSV\": \"train.csv\",\n",
        "    \"obj2id\": {\"f16\": 0, \"cougar\": 1, \"chinook\": 2, \"ah64\": 3, \"f15\": 4, \"seahawk\": 5},\n",
        "    \"id2obj\": {0: \"f16\", 1: \"cougar\", 2: \"chinook\", 3: \"ah64\", 4: \"f15\", 5: \"seahawk\"},\n",
        "    \"h_real\": 720,\n",
        "    \"w_real\": 1280,\n",
        "    \"channel\": 3,\n",
        "    \"w_resize\": 416,\n",
        "    \"h_resize\": 416,\n",
        "    \"grayscale\": False,\n",
        "}"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T22:59:18.224627Z",
          "iopub.execute_input": "2025-02-15T22:59:18.224848Z",
          "iopub.status.idle": "2025-02-15T22:59:18.239115Z",
          "shell.execute_reply.started": "2025-02-15T22:59:18.224817Z",
          "shell.execute_reply": "2025-02-15T22:59:18.238489Z"
        },
        "id": "MJ1Dxf6IK2b9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(32)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'Using {device}')\n",
        "test = torch.ones((100, 100)).to(device)\n",
        "del test\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T22:59:18.240448Z",
          "iopub.execute_input": "2025-02-15T22:59:18.240746Z",
          "iopub.status.idle": "2025-02-15T22:59:18.259952Z",
          "shell.execute_reply.started": "2025-02-15T22:59:18.240715Z",
          "shell.execute_reply": "2025-02-15T22:59:18.259211Z"
        },
        "id": "ksuZ5-PMK2b-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random seed"
      ],
      "metadata": {
        "id": "tftZ7axVK2b_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def reset_seed():\n",
        "    random_seed = 42\n",
        "    torch.backends.cudnn.enabled = True\n",
        "    torch.manual_seed(random_seed)\n",
        "    np.random.seed(random_seed)\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(42)\n",
        "        torch.cuda.manual_seed_all(42)\n",
        "\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "reset_seed()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T22:59:18.260826Z",
          "iopub.execute_input": "2025-02-15T22:59:18.261106Z",
          "iopub.status.idle": "2025-02-15T22:59:18.274068Z",
          "shell.execute_reply.started": "2025-02-15T22:59:18.261077Z",
          "shell.execute_reply": "2025-02-15T22:59:18.273444Z"
        },
        "id": "mnsnfhTgK2cA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function to read CSV"
      ],
      "metadata": {
        "id": "cJRtAiRKK2cB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_train_csv():\n",
        "    \"\"\"\n",
        "    Read the train csv file and return the dataframe with the necessary columns.\n",
        "\n",
        "    Args:\n",
        "    config: Config object\n",
        "\n",
        "    Returns:\n",
        "    df: Dataframe with the necessary columns\n",
        "\n",
        "    usage:\n",
        "    df = read_train_csv(config)\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(osp.join(config[\"DATA_DIR\"], config[\"TRAIN_CSV\"]))\n",
        "    df[\"class_id\"] = df[\"class\"].map(config[\"obj2id\"])\n",
        "    columns_f = [\"filename\", \"xmin\", \"ymin\", \"xmax\", \"ymax\", \"class_id\"]\n",
        "    df = df[columns_f]\n",
        "    df[[\"ymin\", \"ymax\"]] = df[[\"ymin\", \"ymax\"]].div(config[\"h_real\"], axis=0)\n",
        "    df[[\"xmin\", \"xmax\"]] = df[[\"xmin\", \"xmax\"]].div(config[\"w_real\"], axis=0)\n",
        "    return df"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T22:59:18.274875Z",
          "iopub.execute_input": "2025-02-15T22:59:18.275151Z",
          "iopub.status.idle": "2025-02-15T22:59:18.286843Z",
          "shell.execute_reply.started": "2025-02-15T22:59:18.275124Z",
          "shell.execute_reply": "2025-02-15T22:59:18.28612Z"
        },
        "id": "dSE_seNnK2cB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function to get the mean and standard deviation of the channels"
      ],
      "metadata": {
        "id": "0y1YnS7TK2cC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_channels_std(ds):\n",
        "    \"\"\"\n",
        "    Get the standard deviation and mean of each channel in the data.\n",
        "    \"\"\"\n",
        "    means = np.zeros(3)\n",
        "    stds = np.zeros(3)\n",
        "    n_images = 0\n",
        "\n",
        "    for x in ds:\n",
        "        img = x[\"image\"].astype(\n",
        "            np.float32\n",
        "        )  # Asegúrate de que la imagen está en float para cálculos precisos\n",
        "        n_images += 1\n",
        "\n",
        "        for channel in range(3):\n",
        "            channel_pixels = img[..., channel]\n",
        "            # Acumular la suma y suma de cuadrados para calcular la media y desviación estándar\n",
        "            means[channel] += np.mean(channel_pixels)\n",
        "            stds[channel] += np.std(channel_pixels)\n",
        "\n",
        "    # Calcular la media y desviación estándar final\n",
        "    means /= n_images\n",
        "    stds /= n_images\n",
        "\n",
        "    return means, stds"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T22:59:18.287648Z",
          "iopub.execute_input": "2025-02-15T22:59:18.287912Z",
          "iopub.status.idle": "2025-02-15T22:59:18.300734Z",
          "shell.execute_reply.started": "2025-02-15T22:59:18.28788Z",
          "shell.execute_reply": "2025-02-15T22:59:18.300028Z"
        },
        "id": "v_hMEohVK2cC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transforms Functions"
      ],
      "metadata": {
        "id": "S8fPYLMoK2cD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ToTensor(object):\n",
        "    \"\"\"\n",
        "    Convert ndarrays in sample to Tensors for pytorch.\n",
        "\n",
        "    Arguments:\n",
        "        sample: a dictionary containing:\n",
        "            image: sample image in format (H, W, C)\n",
        "    Returns:\n",
        "        the image in (C, H, W) format.\n",
        "    \"\"\"\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        image = sample[\"image\"]\n",
        "\n",
        "        # swap color axis because\n",
        "        # numpy image: H x W x C (0,1,2)\n",
        "        # torch image: C x H x W\n",
        "        image = image.transpose((2, 0, 1))\n",
        "        image = torch.from_numpy(image).float()\n",
        "        sample.update({\"image\": image})\n",
        "        return sample\n",
        "\n",
        "\n",
        "class Normalizer(object):\n",
        "    \"\"\"\n",
        "    Normalize the image by subtracting the mean and dividing by the standard deviation.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, stds, means):\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "\n",
        "            stds: array of length 3 containing the standard deviation of each channel in RGB order.\n",
        "            means: array of length 3 containing the means of each channel in RGB order.\n",
        "        \"\"\"\n",
        "        self.stds = stds\n",
        "        self.means = means\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        \"\"\"\n",
        "        Sample: a dicitonary containing:\n",
        "            image: sample image in format (C, H, W)\n",
        "        Returns:\n",
        "            the image in (C, H, W) format with the channels normalized.\n",
        "        \"\"\"\n",
        "        image = sample[\"image\"]\n",
        "\n",
        "        for channel in range(3):\n",
        "            image[channel] = (image[channel] - self.means[channel]) / self.stds[channel]\n",
        "\n",
        "        sample[\"image\"] = image\n",
        "        return sample\n",
        "\n",
        "\n",
        "class AlbumentationsWrapper(object):\n",
        "    \"\"\"\n",
        "    Albumentations Wrapper\n",
        "\n",
        "    Arguments:\n",
        "        transform: an albumentations transform receiving an image and bounding boxes.\n",
        "\n",
        "    Returns:\n",
        "        the image transformed by the transform object.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, transform):\n",
        "        self.transform = transform\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        transformed = self.transform(\n",
        "            image=sample[\"image\"],\n",
        "            bboxes=sample[\"bbox\"],\n",
        "            # category_ids=sample['class_id']\n",
        "        )\n",
        "        sample[\"image\"] = transformed[\"image\"]\n",
        "        sample[\"bbox\"] = np.array(transformed[\"bboxes\"])\n",
        "        return sample\n",
        "\n",
        "\n",
        "def common_transforms(means, stds):\n",
        "    \"\"\"\n",
        "    Common transformations for the image.\n",
        "    Arguments:\n",
        "        means: array of length 3 containing the means of each channel in RGB order.\n",
        "        stds: array of length 3 containing the standard deviation of each channel in RGB order.\n",
        "    Returns:\n",
        "        a list of transformations.\n",
        "    \"\"\"\n",
        "    return [\n",
        "        ToTensor(),\n",
        "        Normalizer(\n",
        "            means=means,\n",
        "            stds=stds,\n",
        "        ),\n",
        "    ]\n",
        "\n",
        "\n",
        "class TransformComposed:\n",
        "    \"\"\"\n",
        "    Compose a list of transformations.\n",
        "\n",
        "    Arguments:\n",
        "        means: array of length 3 containing the means of each channel in RGB order.\n",
        "        stds: array of length 3 containing the standard deviation of each channel in RGB order.\n",
        "\n",
        "    Returns:\n",
        "        a composed transformation.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, means, stds):\n",
        "        self.means = means\n",
        "        self.stds = stds\n",
        "\n",
        "    def getTransform(self, transforms=[]):\n",
        "        return torchvision.transforms.Compose(\n",
        "            [AlbumentationsWrapper(t) for t in transforms]\n",
        "            + common_transforms(self.means, self.stds)\n",
        "        )"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T22:59:18.303153Z",
          "iopub.execute_input": "2025-02-15T22:59:18.303404Z",
          "iopub.status.idle": "2025-02-15T22:59:18.318394Z",
          "shell.execute_reply.started": "2025-02-15T22:59:18.303384Z",
          "shell.execute_reply": "2025-02-15T22:59:18.317638Z"
        },
        "id": "8hJ28VpDK2cE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Required functions to train a pytorch model"
      ],
      "metadata": {
        "id": "XUVV4U39K2cF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Class to load dataset"
      ],
      "metadata": {
        "id": "UBuP8he0K2cF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform_func_inp_signature = ty.Dict[str, NDArray[np.float_]]\n",
        "transform_func_signature = ty.Callable[\n",
        "    [transform_func_inp_signature],\n",
        "    transform_func_inp_signature\n",
        "]\n",
        "\n",
        "class militarDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Location image dataset\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        df: pd.DataFrame,\n",
        "        root_dir: str,\n",
        "        labeled: bool = True,\n",
        "        transform: ty.Optional[ty.List[transform_func_signature]] = None,\n",
        "        output_size: ty.Optional[tuple] = None  # Añadir parámetro para tamaño de salida\n",
        "    ) -> None:\n",
        "        self.df = df\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.labeled = labeled\n",
        "        self.output_size = output_size  # Almacenar el tamaño de salida\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.df.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx: int) -> transform_func_signature:\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        # Read image\n",
        "        img_name = os.path.join(self.root_dir, self.df.filename.iloc[idx])\n",
        "        #img_name = os.path.join(self.root_dir, self.df.iloc[idx]['filename'])\n",
        "        image = io.imread(img_name)\n",
        "        #image = cv2.imread(img_name)\n",
        "\n",
        "\n",
        "        #print(f\"Dimensiones originales de la imagen: {image.shape}\")  # Agregar para depuración\n",
        "        if image is None:\n",
        "            raise FileNotFoundError(f\"Image not found: {img_name}\")\n",
        "\n",
        "        if image.ndim == 2:  # Si la imagen está en escala de grises\n",
        "            image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)  # Convertir a RGB\n",
        "        elif image.shape[2] == 4:  # Si la imagen es RGBA\n",
        "            image = image[:, :, :3]\n",
        "\n",
        "        # Redimensionar la imagen si se especifica un tamaño de salida\n",
        "        if self.output_size:\n",
        "            image = cv2.resize(image, self.output_size)  # Redimensionar la imagen\n",
        "\n",
        "        sample = {'image': image}\n",
        "\n",
        "        if self.labeled:\n",
        "            # Read labels\n",
        "            img_class = self.df.class_id.iloc[idx]\n",
        "            img_bbox = self.df.iloc[idx, 1:5]\n",
        "\n",
        "            img_bbox = np.array([img_bbox]).astype('float')\n",
        "            img_class = np.array([img_class]).astype('int')\n",
        "            sample.update({'bbox': img_bbox, 'class_id': img_class})\n",
        "\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "\n",
        "        return sample"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T22:59:18.320013Z",
          "iopub.execute_input": "2025-02-15T22:59:18.320271Z",
          "iopub.status.idle": "2025-02-15T22:59:18.336246Z",
          "shell.execute_reply.started": "2025-02-15T22:59:18.320251Z",
          "shell.execute_reply": "2025-02-15T22:59:18.33552Z"
        },
        "id": "UjC5JyiGK2cG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Metrics"
      ],
      "metadata": {
        "id": "2jqFYZIBK2cH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def iou(y_true: Tensor, y_pred: Tensor):\n",
        "    pairwise_iou = torchvision.ops.box_iou(y_true.squeeze(), y_pred.squeeze())\n",
        "    result = torch.trace(pairwise_iou) / pairwise_iou.size()[0]\n",
        "    return result\n",
        "\n",
        "def accuracy(y_true: Tensor, y_pred: Tensor):\n",
        "    pred = torch.argmax(y_pred, axis=-1)\n",
        "    y_true = y_true.squeeze()\n",
        "    correct = torch.eq(pred, y_true).float()\n",
        "    total = torch.ones_like(correct)\n",
        "    result = torch.divide(torch.sum(correct), torch.sum(total))\n",
        "    return result"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T22:59:18.337044Z",
          "iopub.execute_input": "2025-02-15T22:59:18.337251Z",
          "iopub.status.idle": "2025-02-15T22:59:18.354869Z",
          "shell.execute_reply.started": "2025-02-15T22:59:18.337223Z",
          "shell.execute_reply": "2025-02-15T22:59:18.354127Z"
        },
        "id": "Cf2tDHDOK2cH"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss function"
      ],
      "metadata": {
        "id": "tLFGKaK2K2cI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_fn(y_true, y_preds, alpha: float = 0.5):\n",
        "    cls_y_true, cls_y_pred = y_true['class_id'].long(), y_preds['class_id'].float().unsqueeze(-1)\n",
        "    reg_y_true, reg_y_pred = y_true['bbox'].float().squeeze(), y_preds['bbox'].float().squeeze()\n",
        "\n",
        "    cls_loss = F.cross_entropy(cls_y_pred, cls_y_true)\n",
        "\n",
        "    reg_loss = F.mse_loss(reg_y_pred, reg_y_true)\n",
        "    # Adds weights to both tasks\n",
        "    total_loss = (1 - alpha) * cls_loss + alpha * reg_loss\n",
        "    return dict(loss=total_loss, reg_loss=reg_loss,cls_loss=cls_loss)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T22:59:18.3556Z",
          "iopub.execute_input": "2025-02-15T22:59:18.355792Z",
          "iopub.status.idle": "2025-02-15T22:59:18.369944Z",
          "shell.execute_reply.started": "2025-02-15T22:59:18.355774Z",
          "shell.execute_reply": "2025-02-15T22:59:18.36925Z"
        },
        "id": "EtX99zP9K2cI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## callbacks"
      ],
      "metadata": {
        "id": "97HE-L4fK2cI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def printer(logs: ty.Dict[str, ty.Any], epoch: int, seconds:int):\n",
        "    print(f'Epoch #: {epoch} in {seconds} seconds')\n",
        "    for name, value in logs.items():\n",
        "        if not name.endswith(f'{epoch}'):\n",
        "            continue\n",
        "\n",
        "        if type(value) in [float, int]:\n",
        "            value = round(value, 4)\n",
        "        elif type(value) is torch.Tensor:\n",
        "            value = torch.round(value, decimals=4)\n",
        "\n",
        "        print(f'\\t{name} = {value}')\n",
        "    print()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T22:59:18.370663Z",
          "iopub.execute_input": "2025-02-15T22:59:18.370846Z",
          "iopub.status.idle": "2025-02-15T22:59:18.382556Z",
          "shell.execute_reply.started": "2025-02-15T22:59:18.370829Z",
          "shell.execute_reply": "2025-02-15T22:59:18.381885Z"
        },
        "id": "0u8POfyIK2cJ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define model"
      ],
      "metadata": {
        "id": "pqVGuHH8K2cJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_output_shape(\n",
        "    model: nn.Sequential, image_dim: ty.Tuple[int, int, int], device: str = \"cpu\"\n",
        ") -> ty.Tuple[int, int, int]:\n",
        "    return model(torch.rand(*(image_dim)).to(device)).data.shape\n",
        "\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        backbone: nn.Module,\n",
        "        input_shape: ty.Tuple[int, int, int] = (3, 255, 400),\n",
        "        n_classes: int = 6,\n",
        "        device: str = \"cpu\"\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Model with one input (image) and two outputs:\n",
        "            1. Digit classification (classification).\n",
        "            2. Bounding box prediction (regression).\n",
        "\n",
        "        Arguments:\n",
        "            input_shape: input shape of the image in format (C, H, W)\n",
        "            n_classes: number of classes to perfrom classification with\n",
        "            backbone: Initial model to extract features from the image and pass to clasification and regresion heads.\n",
        "\n",
        "        Attributes:\n",
        "            backbone: ConvNet that process the image and\n",
        "            returns a flattened vector with the information of the\n",
        "            activations.\n",
        "\n",
        "            cls_head: MLP that receives the flattened input from the backbone\n",
        "            and predicts the classification logits for the classes (classficiation task).\n",
        "\n",
        "            reg_head: MLP that receives the flattened input from the backbone\n",
        "            and predicts the coordinates of the predicted bounding box (regression task).\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.input_shape = input_shape\n",
        "\n",
        "        # When doing transfer learning, use pretrained model instead of custom backbone\n",
        "        self.backbone = backbone\n",
        "\n",
        "        backbone_output_shape = get_output_shape(self.backbone, [1, *input_shape],device)\n",
        "        backbone_output_features = reduce(lambda x, y: x * y, backbone_output_shape)\n",
        "\n",
        "        self.cls_head = nn.Sequential(\n",
        "            nn.Linear(in_features=backbone_output_features, out_features=768),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(768, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, n_classes),\n",
        "        )\n",
        "\n",
        "        self.reg_head = nn.Sequential(\n",
        "            nn.Linear(in_features=backbone_output_features, out_features=768),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(768, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(128, 4),\n",
        "        )\n",
        "\n",
        "    def forward(self, x: Tensor) -> ty.Dict[str, Tensor]:\n",
        "        features = self.backbone(x)\n",
        "        cls_logits = self.cls_head(features)\n",
        "        pred_bbox = self.reg_head(features)\n",
        "        predictions = {\"bbox\": pred_bbox, \"class_id\": cls_logits}\n",
        "        return predictions"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T22:59:18.383387Z",
          "iopub.execute_input": "2025-02-15T22:59:18.383631Z",
          "iopub.status.idle": "2025-02-15T22:59:18.396029Z",
          "shell.execute_reply.started": "2025-02-15T22:59:18.383604Z",
          "shell.execute_reply": "2025-02-15T22:59:18.395431Z"
        },
        "id": "OSwmj9EDK2cJ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions to train the model"
      ],
      "metadata": {
        "id": "v_hcMPlyK2cK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_logs(\n",
        "    logs: ty.Dict[str, ty.Any],\n",
        "    eval_set: str,\n",
        "    batch:int,\n",
        "    epoch:int,\n",
        "    metrics: ty.Dict[str, ty.Callable[[Tensor, Tensor], Tensor]],\n",
        "    losses: ty.Optional[ty.Dict[str, Tensor]] = None\n",
        ") -> ty.Dict[str, ty.Any]:\n",
        "    \"\"\"\n",
        "         Normalizes the logs for a given evaluation set and batch number, optionally with losses.\n",
        "\n",
        "         Parameters:\n",
        "         - logs (ty.Dict[str, ty.Any]): A dictionary containing the logs to be normalized.\n",
        "         - eval_set (str): The name of the evaluation set (e.g., 'train', 'val', or 'test').\n",
        "         - batch (int): The batch number to normalize the logs.\n",
        "         - epoch (int): The epoch number for the logs.\n",
        "         - metrics (ty.Dict[str, ty.Callable[[Tensor, Tensor], Tensor]]): A dictionary of metrics to be normalized.\n",
        "         - losses (ty.Optional[ty.Dict[str, Tensor]], optional): A dictionary of losses to be normalized. Defaults to None.\n",
        "\n",
        "         Returns:\n",
        "         - ty.Dict[str, ty.Any]: A dictionary containing the normalized logs.\n",
        "    \"\"\"\n",
        "\n",
        "    if losses is not None:\n",
        "        for loss_name, _ in losses.items():\n",
        "            logs[f'{eval_set}_{loss_name}_{epoch}'] /= batch\n",
        "    for task_name in metrics:\n",
        "        for metric_name, metric in metrics[task_name]:\n",
        "            logs[f'{eval_set}_{metric_name}_{epoch}'] /= batch\n",
        "\n",
        "    return logs\n",
        "\n",
        "def evaluate(\n",
        "    logs: ty.Dict[str, ty.Any],\n",
        "    labels: ty.Dict[str, Tensor],\n",
        "    preds: ty.Dict[str, Tensor],\n",
        "    eval_set: str,\n",
        "    metrics: ty.Dict[str, ty.Callable[[Tensor, Tensor], Tensor]],\n",
        "    losses: ty.Optional[ty.Dict[str, Tensor]] = None,\n",
        "    isFirstBatch: bool = True,\n",
        "    epoch:int = 1\n",
        ") -> ty.Dict[str, ty.Any]:\n",
        "    \"\"\"\n",
        "        Evaluates the model's performance on a given dataset and updates the logs with metrics and losses.\n",
        "\n",
        "        Args:\n",
        "            logs (Dict[str, Any]): A dictionary containing the current logs of metrics and losses.\n",
        "            labels (Dict[str, Tensor]): A dictionary containing the ground truth labels for the evaluation.\n",
        "            preds (Dict[str, Tensor]): A dictionary containing the model's predictions for the evaluation.\n",
        "            eval_set (str): The name of the dataset being evaluated (e.g., 'train' or 'validation').\n",
        "            metrics (Dict[str, Callable[[Tensor, Tensor], Tensor]]): A dictionary of metric functions that take\n",
        "                two tensors (predictions and labels) and return a metric value.\n",
        "            losses (Optional[Dict[str, Tensor]]): An optional dictionary containing the calculated losses for\n",
        "                different components of the model. If not provided, it is assumed that there are no losses to evaluate.\n",
        "            isFirstBatch (bool): A flag indicating whether this is the first batch being evaluated. Defaults to True.\n",
        "            epoch (int): The current epoch number in the training process. Defaults to 1.\n",
        "\n",
        "        Returns:\n",
        "            Dict[str, Any]: A dictionary containing the updated logs with computed metrics and losses, including\n",
        "            information about the evaluation set and the current epoch.\n",
        "    \"\"\"\n",
        "    if losses is not None:\n",
        "        for loss_name, loss_value in losses.items():\n",
        "            if isFirstBatch:\n",
        "                logs[f'{eval_set}_{loss_name}_{epoch}'] = loss_value\n",
        "            else:\n",
        "                logs[f'{eval_set}_{loss_name}_{epoch}'] += loss_value\n",
        "\n",
        "    for task_name, label in labels.items():\n",
        "        for metric_name, metric in metrics[task_name]:\n",
        "            value = metric(label, preds[task_name])\n",
        "            if isFirstBatch:\n",
        "                logs[f'{eval_set}_{metric_name}_{epoch}'] = value\n",
        "            else:\n",
        "                logs[f'{eval_set}_{metric_name}_{epoch}'] += value\n",
        "\n",
        "    return logs\n",
        "\n",
        "def step(\n",
        "    model: Model,\n",
        "    optimizer: Optimizer,\n",
        "    batch: militarDataset,\n",
        "    loss_fn: ty.Callable[[ty.Dict[str, torch.Tensor]], torch.Tensor],\n",
        "    device: str,\n",
        "    train: bool = False,\n",
        ") -> ty.Tuple[ty.Dict[str, Tensor], ty.Dict[str, Tensor]]:\n",
        "    \"\"\"\n",
        "      Performs a single training or evaluation step with the given model, optimizer, batch, and loss function.\n",
        "\n",
        "      Parameters:\n",
        "      - model (Model): PyTorch model to perform the step with.\n",
        "      - optimizer (Optimizer): PyTorch optimizer for the model.\n",
        "      - batch (militarDataset): A batch of data to perform the step on.\n",
        "      - loss_fn (ty.Callable[[ty.Dict[str, torch.Tensor]], torch.Tensor]): Loss function for the model.\n",
        "      - device (str): Device to run the model on (e.g., 'cuda' or 'cpu').\n",
        "      - train (bool, optional): Whether this is a training step or an evaluation step. Defaults to False.\n",
        "\n",
        "      Returns:\n",
        "      - input_features (ty.Dict[str, Tensor]): A dictionary containing the input features for the model's forward pass.\n",
        "      - output_values (ty.Dict[str, Tensor]): A dictionary containing the output values from the model's forward pass and the loss function.\n",
        "    \"\"\"\n",
        "\n",
        "    if train:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    #img = batch['image'].to(device)\n",
        "    img = batch.pop('image').to(device)\n",
        "\n",
        "    for k in list(batch.keys()):\n",
        "        batch[k] = batch[k].to(device)\n",
        "\n",
        "    preds = model(img.float())\n",
        "    losses = loss_fn(batch, preds,0.8)\n",
        "    final_loss = losses['loss']\n",
        "\n",
        "    if train:\n",
        "        final_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    return losses, preds\n",
        "\n",
        "\n",
        "def train(\n",
        "    model: Model,\n",
        "    optimizer: Optimizer,\n",
        "    dataset: DataLoader,\n",
        "    eval_datasets: ty.List[ty.Tuple[str, DataLoader]],\n",
        "    loss_fn: ty.Callable[[ty.Dict[str, torch.Tensor]], torch.Tensor],\n",
        "    metrics: ty.Dict[str, ty.Callable[[Tensor, Tensor], Tensor]],\n",
        "    callbacks: ty.List[ty.Callable[[ty.Dict[ty.Any, ty.Any]], None]],\n",
        "    device: str,\n",
        "    epochs: int = 10,\n",
        "    early_stopping_loss_val_patience: int = 1\n",
        ") -> Model:\n",
        "    \"\"\"\n",
        "       Trains a PyTorch model with the specified settings and callbacks.\n",
        "\n",
        "       Parameters:\n",
        "       - model (Model): PyTorch model to be trained.\n",
        "       - optimizer (Optimizer): PyTorch optimizer for the model.\n",
        "       - dataset (DataLoader): DataLoader for the training dataset.\n",
        "       - eval_datasets (ty.List[ty.Tuple[str, DataLoader]]): List of tuples, where each tuple contains the name and DataLoader for a validation dataset.\n",
        "       - loss_fn (ty.Callable[[ty.Dict[str, torch.Tensor]], torch.Tensor]): Loss function for the model.\n",
        "       - metrics (ty.Dict[str, ty.Callable[[Tensor, Tensor], Tensor]]): Dict of metrics to track during training.\n",
        "       - callbacks (ty.List[ty.Callable[[ty.Dict[ty.Any, ty.Any]], None]]): List of callbacks to execute during training.\n",
        "       - device (str): Device to run the model on (e.g., 'cuda' or 'cpu').\n",
        "       - epochs (int, optional): Number of epochs to train the model for. Defaults to 50.\n",
        "       - early_stopping_loss_val_patience (int, optional): Number of epochs to wait model to improve before stop, Default 1\n",
        "\n",
        "       Returns:\n",
        "       - model (Model): Best trained PyTorch model.\n",
        "       - best_epoch: Number of the best epoch.\n",
        "       - logs (Dict[str, ty.Any]): Dictionary with logs of the training\n",
        "   \"\"\"\n",
        "    # Send model to device (GPU or CPU)\n",
        "    model = model.to(device)\n",
        "    logs = dict()\n",
        "    min_loss = np.Inf\n",
        "    best_model = None\n",
        "    best_epoch = 0\n",
        "    num_epochs_patience = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        start_time = time.time()\n",
        "        batchNumber = 0\n",
        "        isFirstBatch = True\n",
        "        model.train()\n",
        "\n",
        "        for batch in dataset:\n",
        "            # Send batch to device\n",
        "            batchNumber += 1\n",
        "            #print(f'batch # {batchNumber}')\n",
        "            losses, preds = step(model, optimizer, batch, loss_fn, device, train=True)\n",
        "            logs = evaluate(logs, batch, preds, 'train', metrics, losses,isFirstBatch,epoch+1)\n",
        "            isFirstBatch = False\n",
        "\n",
        "        logs = normalize_logs(logs, 'train', batchNumber, epoch+1, metrics, losses)\n",
        "\n",
        "        model.eval()\n",
        "        isFirstBatch = True\n",
        "        batchNumber = 0\n",
        "\n",
        "        # Avoids calculating gradients in evaluation dataset.\n",
        "        with torch.no_grad():\n",
        "\n",
        "            for name, dataset in eval_datasets:\n",
        "\n",
        "                for batch in dataset:\n",
        "                    batchNumber += 1\n",
        "                    #print(f'eval batch # {batchNumber}')\n",
        "                    losses, preds = step(model, optimizer, batch, loss_fn, device, train=False)\n",
        "                    logs = evaluate(logs, batch, preds, name, metrics, losses, isFirstBatch,epoch+1)\n",
        "                    isFirstBatch = False\n",
        "\n",
        "                logs = normalize_logs(logs, name, batchNumber, epoch+1, metrics, losses)\n",
        "\n",
        "        end_time = time.time()\n",
        "        seconds = end_time - start_time\n",
        "\n",
        "        for callback in callbacks:\n",
        "            callback(logs, epoch+1, seconds)\n",
        "\n",
        "        # model checkpoint\n",
        "        if logs[f'val_loss_{epoch+1}'] < min_loss:\n",
        "            best_model=copy.deepcopy(model)\n",
        "            best_epoch=epoch+1\n",
        "            torch.save(model, \"best_model.pth\")\n",
        "            #print(f\"Se mejoró el loss de {min_loss} a {logs[f'val_loss_{epoch+1}']}\")\n",
        "            min_loss = logs[f'val_loss_{epoch+1}']\n",
        "            num_epochs_patience = 0\n",
        "        else:\n",
        "            #print(f\"No Se mejoró el loss de {min_loss} a {logs[f'val_loss_{epoch+1}']}\")\n",
        "            num_epochs_patience +=1\n",
        "\n",
        "        if early_stopping_loss_val_patience >-1 and num_epochs_patience > early_stopping_loss_val_patience:\n",
        "            print(f\"----- patience for early stopping {early_stopping_loss_val_patience} exceeded\")\n",
        "            break\n",
        "\n",
        "    return best_model, best_epoch, logs"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T22:59:18.396885Z",
          "iopub.execute_input": "2025-02-15T22:59:18.397097Z",
          "iopub.status.idle": "2025-02-15T22:59:18.415969Z",
          "shell.execute_reply.started": "2025-02-15T22:59:18.397079Z",
          "shell.execute_reply": "2025-02-15T22:59:18.415268Z"
        },
        "id": "fXB489NyK2cL"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split train and validation"
      ],
      "metadata": {
        "id": "fLMIioxdK2cM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reset_seed()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T22:59:18.416856Z",
          "iopub.execute_input": "2025-02-15T22:59:18.41715Z",
          "iopub.status.idle": "2025-02-15T22:59:18.434565Z",
          "shell.execute_reply.started": "2025-02-15T22:59:18.417101Z",
          "shell.execute_reply": "2025-02-15T22:59:18.433907Z"
        },
        "id": "WrJs0NYkK2cN"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df = read_train_csv()\n",
        "train_df, val_df = train_test_split(\n",
        "    df, stratify=df[\"class_id\"], test_size=0.25, random_state=42\n",
        ")\n",
        "print(f'training set shape: {train_df.shape}')\n",
        "print(f'validation set shape: {val_df.shape}')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T22:59:18.435221Z",
          "iopub.execute_input": "2025-02-15T22:59:18.435457Z",
          "iopub.status.idle": "2025-02-15T22:59:18.463197Z",
          "shell.execute_reply.started": "2025-02-15T22:59:18.435438Z",
          "shell.execute_reply": "2025-02-15T22:59:18.462601Z"
        },
        "id": "7kVtWL6sK2cN"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define transforms"
      ],
      "metadata": {
        "id": "_zkFdaBNK2cO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "root_dir = osp.join(config[\"DATA_DIR\"], config[\"IMG_DIR\"])\n",
        "train_ds = militarDataset(train_df, root_dir)\n",
        "means, stds = get_channels_std(train_ds)\n",
        "common_transforms_I = common_transforms(means,stds)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T22:59:18.463872Z",
          "iopub.execute_input": "2025-02-15T22:59:18.464055Z",
          "iopub.status.idle": "2025-02-15T22:59:21.019033Z",
          "shell.execute_reply.started": "2025-02-15T22:59:18.464038Z",
          "shell.execute_reply": "2025-02-15T22:59:21.018383Z"
        },
        "id": "P0VIuhtuK2cO"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "bbox_params = A.BboxParams(format=\"albumentations\", label_fields=[])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T22:59:21.01977Z",
          "iopub.execute_input": "2025-02-15T22:59:21.019998Z",
          "iopub.status.idle": "2025-02-15T22:59:21.023651Z",
          "shell.execute_reply.started": "2025-02-15T22:59:21.019978Z",
          "shell.execute_reply": "2025-02-15T22:59:21.022869Z"
        },
        "id": "iVHzuoKXK2cO"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_augmentations = A.Compose([\n",
        "    A.HorizontalFlip(p=1),\n",
        "    A.Rotate(limit=45, p=0.5),\n",
        "    A.AutoContrast(p=0),\n",
        "    A.Defocus(p=1),\n",
        "    A.Downscale(p=1),\n",
        "    A.GaussNoise(p=0),\n",
        "    A.GaussianBlur(p=0),\n",
        "    A.HueSaturationValue(p=0),\n",
        "    A.ISONoise(p=0),\n",
        "    A.PlanckianJitter(p=0),\n",
        "    A.PlasmaShadow(p=0),\n",
        "    A.Posterize(p=0),\n",
        "    A.RandomFog(p=0),\n",
        "    A.RandomSnow(p=0),\n",
        "    A.RandomSunFlare(p=0),\n",
        "    A.SaltAndPepper(p=0),\n",
        "    A.Sharpen(p=0),\n",
        "    A.ZoomBlur(p=0)\n",
        "    ],\n",
        "    bbox_params=bbox_params\n",
        ")\n",
        "\n",
        "train_transforms = torchvision.transforms.Compose(\n",
        "    [\n",
        "        AlbumentationsWrapper(train_data_augmentations),\n",
        "    ] + common_transforms_I\n",
        ")\n",
        "\n",
        "eval_transforms = torchvision.transforms.Compose(common_transforms_I)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T22:59:21.024477Z",
          "iopub.execute_input": "2025-02-15T22:59:21.024724Z",
          "iopub.status.idle": "2025-02-15T22:59:21.048221Z",
          "shell.execute_reply.started": "2025-02-15T22:59:21.024692Z",
          "shell.execute_reply": "2025-02-15T22:59:21.047388Z"
        },
        "id": "a3_SaJbiK2cP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer Learning"
      ],
      "metadata": {
        "id": "N5Ka4rRGK2cP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FeatureExtractor(nn.Module):\n",
        "    def __init__(self, model):\n",
        "        super(FeatureExtractor, self).__init__()\n",
        "        # Extract VGG-16 Feature Layers\n",
        "        self.features = list(model.features)\n",
        "        self.features = nn.Sequential(*self.features)\n",
        "        # Extract VGG-16 Average Pooling Layer\n",
        "        self.pooling = model.avgpool\n",
        "        # Convert the image into one-dimensional vector\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # It will take the input 'x' until it returns the feature vector called 'out'\n",
        "        out = self.features(x)\n",
        "        out = self.pooling(out)\n",
        "        out = self.flatten(out)\n",
        "        out = self.dropout(out)\n",
        "        return out"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T22:59:21.049352Z",
          "iopub.execute_input": "2025-02-15T22:59:21.049723Z",
          "iopub.status.idle": "2025-02-15T22:59:21.056575Z",
          "shell.execute_reply.started": "2025-02-15T22:59:21.049669Z",
          "shell.execute_reply": "2025-02-15T22:59:21.055498Z"
        },
        "id": "8euW4V36K2cQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clasification models"
      ],
      "metadata": {
        "id": "Xw9KdN4dK2cQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following classification models are available, with or without pre-trained weights:\n",
        "\n",
        "* AlexNet\n",
        "* ConvNeXt\n",
        "* DenseNet\n",
        "* EfficientNet\n",
        "* EfficientNetV2\n",
        "* GoogLeNet\n",
        "* Inception V3\n",
        "* MaxVit\n",
        "* MNASNet\n",
        "* MobileNet V2\n",
        "* MobileNet V3\n",
        "* RegNet\n",
        "* ResNet\n",
        "* ResNeXt\n",
        "* ShuffleNet V2\n",
        "* SqueezeNet\n",
        "* SwinTransformer\n",
        "* VGG\n",
        "* VisionTransformer\n",
        "* Wide ResNet"
      ],
      "metadata": {
        "id": "qlTSpqxTK2cc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EfficientNetV2"
      ],
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "tY68bWdDK2cc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from torchvision.models import efficientnet_v2_l, EfficientNet_V2_L_Weights\n",
        "\n",
        "# Load the efficient net v2 model\n",
        "# env2_model = efficientnet_v2_l(weights=EfficientNet_V2_L_Weights.DEFAULT)\n",
        "# pretrained_model = FeatureExtractor(env2_model).to(device)\n",
        "# pretrained_model"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T22:59:22.744004Z",
          "iopub.execute_input": "2025-02-15T22:59:22.744347Z",
          "iopub.status.idle": "2025-02-15T22:59:22.747785Z",
          "shell.execute_reply.started": "2025-02-15T22:59:22.744287Z",
          "shell.execute_reply": "2025-02-15T22:59:22.746898Z"
        },
        "id": "N_ZSmqPSK2cd"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### vgg16"
      ],
      "metadata": {
        "id": "L_JoRbvdK2cd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import vgg16, VGG16_Weights\n",
        "\n",
        "\n",
        "# Load the vgg16 model\n",
        "vgg16_model = vgg16(weights=VGG16_Weights.DEFAULT, progress=True)\n",
        "pretrained_model = FeatureExtractor(vgg16_model).to(device)\n",
        "pretrained_model"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T22:59:21.057472Z",
          "iopub.execute_input": "2025-02-15T22:59:21.057798Z",
          "iopub.status.idle": "2025-02-15T22:59:22.743095Z",
          "shell.execute_reply.started": "2025-02-15T22:59:21.057764Z",
          "shell.execute_reply": "2025-02-15T22:59:22.742387Z"
        },
        "id": "mwOk3fahK2cd"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Object detection"
      ],
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "HargH0yzK2ce"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Faster R-CNN\n",
        "* FCOS\n",
        "* RetinaNet\n",
        "* SSD\n",
        "* SSDlite"
      ],
      "metadata": {
        "id": "bGjG9wx5K2ce"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Retina Net"
      ],
      "metadata": {
        "id": "5GPhSynMK2ce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from torchvision.models.detection import retinanet_resnet50_fpn_v2, RetinaNet_ResNet50_FPN_V2_Weights\n",
        "\n",
        "#retina = retinanet_resnet50_fpn_v2(weights=RetinaNet_ResNet50_FPN_V2_Weights.DEFAULT, progress=True)\n",
        "#pretrained_model = FeatureExtractor(retina).to(device)\n",
        "#pretrained_model"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T22:59:22.751052Z",
          "iopub.execute_input": "2025-02-15T22:59:22.751265Z",
          "iopub.status.idle": "2025-02-15T22:59:22.76494Z",
          "shell.execute_reply.started": "2025-02-15T22:59:22.751246Z",
          "shell.execute_reply": "2025-02-15T22:59:22.76419Z"
        },
        "id": "RLUOXPooK2ce"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialize model"
      ],
      "metadata": {
        "id": "RO8NA3rLK2cf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds[0]['image'].shape"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T22:59:22.766025Z",
          "iopub.execute_input": "2025-02-15T22:59:22.766237Z",
          "iopub.status.idle": "2025-02-15T22:59:22.791953Z",
          "shell.execute_reply.started": "2025-02-15T22:59:22.766219Z",
          "shell.execute_reply": "2025-02-15T22:59:22.791351Z"
        },
        "id": "awUA1-WSK2cf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Hparams\n",
        "batch_size = 32\n",
        "lr = 0.001\n",
        "w = 256\n",
        "h = 256\n",
        "c = 3\n",
        "\n",
        "# Data\n",
        "train_ds = militarDataset(train_df, root_dir=root_dir, transform=train_transforms,output_size=(w,h))\n",
        "val_ds = militarDataset(val_df, root_dir=root_dir, transform=eval_transforms,output_size=(w,h))\n",
        "\n",
        "train_data = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=cpu_count())\n",
        "val_data = DataLoader(val_ds, batch_size=batch_size, num_workers=cpu_count())\n",
        "\n",
        "# Model\n",
        "model = Model(pretrained_model,(c,h,w),device=device).to(device)\n",
        "summary(model, model.input_shape)\n",
        "\n",
        "# Optimizer\n",
        "optimizer = torch.optim.Adam(lr=lr, params=model.parameters())"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T22:59:22.792747Z",
          "iopub.execute_input": "2025-02-15T22:59:22.793025Z",
          "iopub.status.idle": "2025-02-15T22:59:23.186701Z",
          "shell.execute_reply.started": "2025-02-15T22:59:22.792997Z",
          "shell.execute_reply": "2025-02-15T22:59:23.185806Z"
        },
        "id": "KPjGUu3JK2cf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "CbzDyTTUK2cg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model, best_epoch,logs = train(\n",
        "    model,\n",
        "    optimizer,\n",
        "    train_data,\n",
        "    eval_datasets=[('val', val_data)],\n",
        "    loss_fn=loss_fn,\n",
        "    metrics={\n",
        "        'bbox': [('iou', iou)],\n",
        "        'class_id': [('accuracy', accuracy)]\n",
        "    },\n",
        "    callbacks=[printer],\n",
        "    device=device,\n",
        "    epochs=50,\n",
        "    early_stopping_loss_val_patience=5\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T22:59:23.187792Z",
          "iopub.execute_input": "2025-02-15T22:59:23.188122Z",
          "iopub.status.idle": "2025-02-15T23:00:56.859798Z",
          "shell.execute_reply.started": "2025-02-15T22:59:23.188086Z",
          "shell.execute_reply": "2025-02-15T23:00:56.858719Z"
        },
        "id": "FdxxEIMoK2cg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot epochs"
      ],
      "metadata": {
        "id": "RusdaEDAK2ch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_losses_and_accuracies(logs: ty.Dict[str, ty.Any]):\n",
        "    epochs = []\n",
        "    train_loss = []\n",
        "    val_loss = []\n",
        "    train_accuracy = []\n",
        "    val_accuracy = []\n",
        "    train_iou = []\n",
        "    val_iou = []\n",
        "\n",
        "    # Extraer los datos del diccionario\n",
        "    for key, value in logs.items():\n",
        "        if \"train_loss\" in key:\n",
        "            epoch = int(key.split('_')[2])\n",
        "            epochs.append(epoch)\n",
        "            train_loss.append(value.cpu().detach().numpy())\n",
        "        elif \"val_loss\" in key:\n",
        "            # Guardar el valor de val_loss\n",
        "            val_loss.append(value.cpu().numpy())\n",
        "        elif \"train_accuracy\" in key:\n",
        "            # Guardar el valor de train_accuracy\n",
        "            train_accuracy.append(value.cpu().detach().numpy())\n",
        "        elif \"val_accuracy\" in key:\n",
        "            # Guardar el valor de val_accuracy\n",
        "            val_accuracy.append(value.cpu().numpy())\n",
        "        elif \"train_iou\" in key:\n",
        "            # Guardar el valor de train_iou\n",
        "            train_iou.append(value.cpu().detach().numpy())\n",
        "        elif \"val_iou\" in key:\n",
        "            # Guardar el valor de val_iou\n",
        "            val_iou.append(value.cpu().numpy())\n",
        "\n",
        "    # Ordenar las listas por épocas\n",
        "    epochs = sorted(set(epochs))  # Asegurarse de que las épocas sean únicas y ordenadas\n",
        "    train_loss = [train_loss[i-1] for i in epochs]  # Ajustar los índices\n",
        "    val_loss = [val_loss[i-1] for i in epochs]  # Ajustar los índices\n",
        "    train_accuracy = [train_accuracy[i-1] for i in epochs]  # Ajustar los índices\n",
        "    val_accuracy = [val_accuracy[i-1] for i in epochs]  # Ajustar los índices\n",
        "    train_iou = [train_iou[i-1] for i in epochs]  # Ajustar los índices\n",
        "    val_iou = [val_iou[i-1] for i in epochs]  # Ajustar los índices\n",
        "\n",
        "    # Crear el gráfico\n",
        "    plt.figure(figsize=(12, 8))\n",
        "\n",
        "    # Graficar Loss\n",
        "    plt.subplot(2, 2, 1)\n",
        "    plt.plot(epochs, train_loss, marker='o', label='Train Loss')\n",
        "    plt.plot(epochs, val_loss, marker='o', label='Val Loss')\n",
        "    plt.title('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "\n",
        "    # Graficar Accuracy\n",
        "    plt.subplot(2, 2, 2)\n",
        "    plt.plot(epochs, train_accuracy, marker='o', label='Train Accuracy')\n",
        "    plt.plot(epochs, val_accuracy, marker='o', label='Val Accuracy')\n",
        "    plt.title('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "\n",
        "    # Graficar IoU\n",
        "    plt.subplot(2, 2, 3)\n",
        "    plt.plot(epochs, train_iou, marker='o', label='Train IoU')\n",
        "    plt.plot(epochs, val_iou, marker='o', label='Val IoU')\n",
        "    plt.title('IoU')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('IoU')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "\n",
        "    # Ajustar el layout\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Mostrar el gráfico\n",
        "    plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T23:00:56.861026Z",
          "iopub.execute_input": "2025-02-15T23:00:56.861407Z",
          "iopub.status.idle": "2025-02-15T23:00:56.877593Z",
          "shell.execute_reply.started": "2025-02-15T23:00:56.861373Z",
          "shell.execute_reply": "2025-02-15T23:00:56.876818Z"
        },
        "id": "v62_T5OQK2ch"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'best model found on epoch {best_epoch}')\n",
        "plot_losses_and_accuracies(logs)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T23:00:56.878486Z",
          "iopub.execute_input": "2025-02-15T23:00:56.87877Z",
          "iopub.status.idle": "2025-02-15T23:00:57.494673Z",
          "shell.execute_reply.started": "2025-02-15T23:00:56.878731Z",
          "shell.execute_reply": "2025-02-15T23:00:57.493842Z"
        },
        "id": "WAYQYsQqK2ch"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save"
      ],
      "metadata": {
        "id": "VVbm7fD6K2ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, \"pretrained_model.pth\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T23:00:57.495611Z",
          "iopub.execute_input": "2025-02-15T23:00:57.495893Z",
          "iopub.status.idle": "2025-02-15T23:00:57.885171Z",
          "shell.execute_reply.started": "2025-02-15T23:00:57.495866Z",
          "shell.execute_reply": "2025-02-15T23:00:57.884511Z"
        },
        "id": "PJ1voZ4FK2ci"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Submission"
      ],
      "metadata": {
        "id": "hVHx8A10K2cj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform inference on cpu in order to avoid memory problems\n",
        "device = 'cuda'\n",
        "model = model.to(device)\n",
        "\n",
        "test_root_dir = osp.join(config['DATA_DIR'], \"images/images\")\n",
        "test_df = pd.read_csv(osp.join(config['DATA_DIR'], \"test.csv\"))\n",
        "\n",
        "test_ds = militarDataset(test_df, root_dir=test_root_dir, labeled=False, transform=eval_transforms,output_size=(w,h))#\n",
        "test_data = DataLoader(test_ds, batch_size=1, num_workers=cpu_count(), shuffle=False)\n",
        "\n",
        "class_preds = []\n",
        "bbox_preds = []\n",
        "\n",
        "for batch in test_data:\n",
        "    batch_preds = model(batch['image'].float().to(device))\n",
        "\n",
        "    class_pred = batch_preds['class_id'].argmax(-1).detach().cpu().numpy()\n",
        "    bbox_pred = batch_preds['bbox'].detach().cpu().numpy()\n",
        "\n",
        "    class_preds.append(class_pred.squeeze())\n",
        "    bbox_preds.append(bbox_pred.squeeze())"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T23:00:57.886024Z",
          "iopub.execute_input": "2025-02-15T23:00:57.886268Z",
          "iopub.status.idle": "2025-02-15T23:00:58.580637Z",
          "shell.execute_reply.started": "2025-02-15T23:00:57.886247Z",
          "shell.execute_reply": "2025-02-15T23:00:58.579625Z"
        },
        "id": "DH5mP81lK2cj"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class_preds = np.array(class_preds)\n",
        "bbox_preds = np.array(bbox_preds)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T23:00:58.581753Z",
          "iopub.execute_input": "2025-02-15T23:00:58.582074Z",
          "iopub.status.idle": "2025-02-15T23:00:58.586805Z",
          "shell.execute_reply.started": "2025-02-15T23:00:58.582045Z",
          "shell.execute_reply": "2025-02-15T23:00:58.585914Z"
        },
        "id": "DcjjzNrsK2ck"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.DataFrame(\n",
        "    index=test_df.filename,\n",
        "    data={\n",
        "        'class_id': class_preds,\n",
        "        }\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T23:00:58.587733Z",
          "iopub.execute_input": "2025-02-15T23:00:58.587991Z",
          "iopub.status.idle": "2025-02-15T23:00:58.60196Z",
          "shell.execute_reply.started": "2025-02-15T23:00:58.587963Z",
          "shell.execute_reply": "2025-02-15T23:00:58.601172Z"
        },
        "id": "BqTqmf38K2ck"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "submission[\"xmin\"] = bbox_preds[:, 0]*config['w_real']\n",
        "submission[\"ymin\"] = bbox_preds[:, 1]*config['h_real']\n",
        "submission[\"xmax\"] = bbox_preds[:, 2]*config['w_real']\n",
        "submission[\"ymax\"] = bbox_preds[:, 3]*config['h_real']\n",
        "submission['class']=submission['class_id'].replace(config['id2obj'])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T23:00:58.602663Z",
          "iopub.execute_input": "2025-02-15T23:00:58.602921Z",
          "iopub.status.idle": "2025-02-15T23:00:58.619309Z",
          "shell.execute_reply.started": "2025-02-15T23:00:58.6029Z",
          "shell.execute_reply": "2025-02-15T23:00:58.618503Z"
        },
        "id": "SsQRE8qvK2cl"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "submission['class'].value_counts()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T23:00:58.620125Z",
          "iopub.execute_input": "2025-02-15T23:00:58.620415Z",
          "iopub.status.idle": "2025-02-15T23:00:58.644043Z",
          "shell.execute_reply.started": "2025-02-15T23:00:58.620382Z",
          "shell.execute_reply": "2025-02-15T23:00:58.643202Z"
        },
        "id": "-jmr2QMGK2cm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "submission.to_csv('submission.csv')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T23:00:58.644877Z",
          "iopub.execute_input": "2025-02-15T23:00:58.645169Z",
          "iopub.status.idle": "2025-02-15T23:00:58.66388Z",
          "shell.execute_reply.started": "2025-02-15T23:00:58.64514Z",
          "shell.execute_reply": "2025-02-15T23:00:58.66329Z"
        },
        "id": "iOhlPPvoK2cm"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}